\documentclass[
    iict, % Saisir le nom de l'institut rattaché
    il, % Saisir le nom de l'orientation
    %confidential, % Décommentez si le travail est confidentiel
]{heig-tb}

\usepackage{titlesec}

\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Huge}


\usepackage[nooldvoltagedirection,european,americaninductors]{circuitikz}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{lastpage}

%\signature{mbernasconi.svg} TODO

\makenomenclature
\makenoidxglossaries
\makeindex

\addbibresource{bibliography.bib}

\input{nomenclature}
\input{acronyms}
\input{glossary}
\input{meta}

\surroundwithmdframed{minted}

%% Début du document
\begin{document}
\selectlanguage{french}
\maketitle
\frontmatter
\clearemptydoublepage

%% Requis par les dispositions générales des travaux de Bachelor
\preamble
\let\cleardoublepage\clearpage
\authentification
\let\cleardoublepage\clearpage

%% Résumé / Version abbrégée
\begin{abstract}
    \input{abstract}
\end{abstract}

%% Sommaire et tables
\clearemptydoublepage
{
    \tableofcontents
    \let\cleardoublepage\clearpage
    \listoffigures
    \let\cleardoublepage\clearpage
    \listoftables
    \let\cleardoublepage\clearpage
    \listoflistings
}

\printnomenclature
\clearemptydoublepage
\pagenumbering{arabic}

\pagestyle{fancy}

\fancyhf{}
\renewcommand\headrulewidth{1pt}

\fancyhead[R]{Support du langage UON}
\fancyhead[L]{\itshape\nouppercase{\leftmark}}

\renewcommand\footrulewidth{1pt}

\fancypagestyle{plain}{%
    \fancyfoot[R]{Page \thepage/\pageref{LastPage}}
}
\fancyfoot[R]{Page \thepage/\pageref{LastPage}}

\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


%% Contenu
\mainmatter
\chapter{Introduction}
Ce projet de Bachelor consiste à fournir du support pour le nouveau langage de sérialisation UON, sous VsCode. Ce projet se veut expérimental. C'est-à-dire qu'aucun cadre précis sur sa réalisation n'a été établi et que les approches choisis sont libres tant qu'elles respectent le cahier des charges.
Dans les chapitres suivants, nous allons voir ce qui est fourni par VsCode pour élaborer et déployer une extension.
Les éléments à prendre en compte pour pouvoir fournir du support pour un langage.
Les aspects du langage UON à considérer dans le cadre de ce projet.
Et présenterons en détail l'implémentation d'une extension ainsi que ses fonctionnalités. Puis détaillerons les tests effectués.

\let\cleardoublepage\clearpage

\chapter{Cahier des charges}
Voici ci-dessous un résumé du cahier des charges :

\textbf{Extension}
\begin{itemize}
    \item Code source publié sur Github
    \item Fournir une intégration continue
    \item Déployer l'extension sur le marketplace
\end{itemize}

\textbf{Fonctionnalités à implémenter}
\begin{itemize}
    \item Syntax highligting
    \item Auto-complétion
    \item Document Outlining
    \item Hover Information
\end{itemize}

\textbf{Si le temps le permet}
\begin{itemize}
    \item Lint
    \item Formatter
    \item Converter
\end{itemize}

\vspace{\parskip}

Ce projet se focalise uniquement sur l'éditeur de code VScode.

Une extension peut être écrite en Typescript ou en Javascript.
Nous choisirons le Typescript car Vscode recommande ce langage.

Concernant les fonctionnalités à implémenter. Il n'y avait pas de contraintes de choix.
Nous avons donc séléctionner les fonctionnalités attendues en choisissant celles paraissant utiles à avoir dans un premier temps et en prenant en considération la contrainte de temps.

\chapter{Pré-étude}

\section{VScode}
Visual Studio Code (ou VScode) est un éditeur de code qui est pensé pour être extensible (De L'UI à l'expérience utilisateur).
Presque tout peut être customisé et améliorer à travers de \href{https://code.visualstudio.com/api/extension-capabilities/overview}{L'Extension API}.

L'Extension API nous permet donc gérér un certain nombre de choses.
On se focalisera sur le theming , les fonctionnalités de langages, la publication de l'extension et les tests.

VScode fourni pleins de documentations détaillées sur plein de sujets, guides, ainsi que des examples de codes.
Il s'agit donc évidemment de la source principales des explications données dans ce document concernant ce qui touche à cette éditeur.

\subsection{Extension Anatomy}
Il y a 3 concepts crucials à comprendre pour réaliser une extension.
\begin{itemize}
    \item \textbf{Activation Events}: Des événements à partir desquels l'extension devient active.
    \item \textbf{Contribution Points}: Des déclarations statiques qui sont faitent dans le manifeste d'extension "package.json" pour étendre l'extension.
    \item \textbf{VS Code API}: Un ensemble d'API JavaScript que nous pouvons invoquer dans le code.
\end{itemize}

En général, l'extension est une combinaison de plusieurs Conntribution Point et de VS code API pour étendre les fonctionnalité de VSCode.

\subsubsection{Extension File Structure}
La structure d'une extension est la suivante :
\begin{lstlisting}
    .
    ├── .vscode
    │   ├── launch.json     // Config for launching and debugging the extension
    │   └── tasks.json      // Config for build task that compiles TypeScript
    ├── .gitignore          // Ignore build output and node_modules
    ├── README.md           // Readable description of your extension's functionality
    ├── src
    │   └── extension.ts    // Extension source code
    ├── package.json        // Extension manifest
    ├── tsconfig.json       // TypeScript configuration
\end{lstlisting}

Extension Manifest(package.json):
Chaque extension doit contenir un fichier package.json. En plus des champs propre à Node.js, on peut spécifier des scripts, dépendances de dévelopement et des champs spécifiques à Vscode.

Extension Entry File(Extension.js) :
Il s'agit du fichier prinicpale de l'extension.
De base il contient 2 fonctions : "activate" et "deactivate".
La fonction activate est executé à l'activation de notre extension par un Activation Event. On définira ici le code à exécuter.
La fonction deactivate  ext exécuté lorsque l'application devient innactive. Et sert principalement à nettoyer le code avant la désactivation de l'extension

\textbf{Remarque} : Le niveau de customisation est assez élevé. La seul limitation souvent indiquée et qu'il n'est pas possible d'accéder au DOM de l'éditeur.

Nous avons donc vu les briques de bases pour la conception d'une extension. Cette base est suffisante pour nous dans un premier temps.

Ce rapport n'ayant pas pour vocation d'expliquer tout ce qui est possible de faire. Si vous souhaitez vous renseinger d'avantages sur ce sujet, vous pouvez le faire \href{https://code.visualstudio.com/api}{ici}.

\subsection{Support de langage}
VsCode fournit la possibilité d'ajouter du support pour un nouveau langage de programmation au travers d'implémentation de fonctionnalités. Ces fonctionnalités peuvent être classées en 2 catégories :

\section{Declarative language features}
Elles ajoutent un support d'édition de texte de base pour un langage de programmation.
Par exemple, les éléments suivants :

\begin{itemize}
    \item Syntax highlighting
    \item Snippet completion
    \item Bracket matching
    \item Bracket autoclosing
    \item Bracket autosurrounding
    \item Comment toggling
    \item Auto indentation
    \item Folding (by markers)
\end{itemize}

Il s'agit de fonctionnalités implémentées à l'aide de fichier de configuration.
Puis, elles doivent être enregistrées dans le fichier package.json du projet sous le champ "contributes" \space \href{https://code.visualstudio.com/api/references/contribution-points}{ Contribution Point}.

\section{Programmatic language features}
Il s'agit de fonctionnalité plus riche donc plus complexe à implémenter (p.ex : "Hovers", "Go to Definition", "diagnostic errors", "IntelliSense" \space et "CodeLens".
Il y a 2 approches pour les implémenter.
La première est d'utiliser l'api \href{https://code.visualstudio.com/api/references/vscode-api#languages}{vscode.languages.*} qui expose des interfaces permettant de réaliser directement les fonctionnalités.
La seconde est de fournir nous-mêmes ces fonctions au travers d'un langage serveur.
Les avantages souvent mentionnés de la deuxième solution et que le langage server peut être écrit avec le langage que l'on souhaite et que cela permet aussi à d'autres éditeurs de texte compatibles avec le langage server d'utiliser ses fonctionnalités sans devoir les implémenter de nouveau. Mais comme points négatifs cette approche est plus complexe à implémenter et dans notre cas n'est pas un choix primordial.

\subsection{Langage server}
Pour être utiliser sur VSCode, un langage server à 2 partis :
\begin{itemize}
    \item \textbf{Un client} : C'est une extension écrite en Javascript ou Typescript qui à accès à tous les endpoints de VScode
    \item \textbf{Langage server} : Un outil d'analyse linguistique fonctionnant dans un processus séparé lancé
\end{itemize}

Le client et le serveur communiquent à l'aide du protocole LSP (pour "language server") dès que des informations riches devraient être fournies à l'éditeur.
Le langage server devrait donc ensuite pouvoir "consommer" un parser pour traiter les fonctionnalités. C'est-à-dire être capable d'analyser un AST et de fournir une réponse adéquate.
L'implémentation d'un tel serveur peut être libre, mais des implémentations existent déjà. Telle que "LSP4" implémenté en Java ou  "Vscode-languageserver-node" implémenté en Typescript qui n'est pas exclusivement réservé à VsCode comme son nom pourrait l'indiquer.
On remarque donc avec cette approche que 2 composantes existent (Le client et le serveur)
Un langage server peut être utilisé sur d'autre éditeur compatible. Mais le client devra être implémenté de nouveau.

\subsection{VsCode API (Direct implementation)}
L'autre approche et donc de communiquer directement avec l'api en s'inscrivant à des providers.
L'éditeur fera les requêtes aux providers lorsque nécessaire.

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/api-vscode.png}
    \end{center}
    \caption[API]{\label{test} blabla...}
\end{figure}

Ce schéma ci-dessus montre la correspondance des méthodes entre la première et seconde approche.
Beaucoup de possibilités et donc fourni, mais nous utiliserons uniquement les providers suivants :

\begin{itemize}
    \item \textbf{registerCompletionItemProvider}
          \subitem Pour afficher des suggestions de complétions
    \item \textbf{registerHoverProvider}
          \subitem Pour gérer le hover
    \item \textbf{registerDocumentSymbolProvider}
          \subitem Pour afficher les éléments dans la Outline View
\end{itemize}

\subsection{Parser}
Pour fournir des fonctionnalités de langue, une approche souvent pratiqué et l'utilisation d'un parser.
Car les fonctionnalité se baseront sur L'AST qu'il générera.

Cependant dans le cadre de son utilisation dans un éditeur/IDE, il devrait être "fault tolerant". Le parseur doit pouvoir générér un AST (abstract syntax tree) qui à du sens depuis du code incomplet.

Il ne devrait pas s'arrêter dès la première erreur. Car la plupart du temps, le code dans l'éditeur est incomplet et syntaxiquement incorrect.
Et les développeurs s'attendent tout de même à ce que la complétion automatique et et d'autres fonctions de langue fonctionnent.

\subsection{Grammaire}
Il faudra aussi élaborer une grammaire pour le langage de sérialisation UON utilisable par le parser.
Pour faciliter l'étape de l'analyse syntaxique ("Parsing"), cette grammaire pourrait être plus permissive, en particulier concernant les types attendus (Terminaux). Ainsi si l'utilisateur entre une valeur dont le type attendu est incorrect (par rapport aux spécifications du langage). Nous n'avons pas à traiter ce type d'erreur.

\section{Recherche d'extensions similaires}
Fournir du support pour un nouveau langage est une tâche relativement courante.
Il est donc relativement simple de trouver des extensions proposant un objectif similaire sur la marketplace.
Évidemment c'est donc une des premières choses qui ont été faites. Regarder les extensions similaires et particulièrement ceux touchant à des langages de sérialisation.

\subsection{Yaml}
UON étant un langage proche de YAML c'est vers son extension que je me suis dirigée en premier. Car il n'existe pas d'extension officielle, similaire pour le langage JSON.
Cependant j'ai vite compris que cela n'allait pas forcément être aussi évident. Car contrairement à JSON et YAML, UON intègre directement dans son langage des types définis. Ce qui fait que l'auto-complétion fournit par des JSON Schema dans l'extension YAML n'est pas vraiment applicable pour notre cas.
Aussi pour l'outline view. La création d'un symbol tree se fait à l'aide de fonction utilitaire très "privée" et complexe à reprendre est à adapté. En cherchant, j'ai vu que JSON utilise ces mêmes fonctions.
Cette direction a donc été écarté.

\section{Choix technologiques}
Comme expliqué précédemment, la catégorie d'une fonctionnalité va influencer son implémentation sous VsCode. Mais certaines de ces fonctionnalités pourraient être implémentées selon l'une ou l'autre approche en fonction de la complexité souhaitée, par exemple le  "code folding" ou "autocompletion". Il est donc possible que lors du déroulement du projet que la solution jugée la plus intéressante soit privilégiée.

\subsection{Grammaire}
Une grammaire simplifiée de UON sera l'approche privilégiée au départ. Si nécessaire, elle pourrait être étendue.

\subsection{Parser}
Des outils permettant la génération d'un parser en fonction d'une grammaire existent et seront privilégiés. Si cette approche échoue alors soit l'implémentation d'un parser simple sera effectuée ou il faudra envisager une piste alternative.

\subsection{API}
L'implémentation d'un langage serveur n'étant pas une priorité et pour se concentrer sur la réalisation des fonctionnalités, l'approche de contacter directement l'api de VsCode sera choisi. Si le temps le permet, toute la logique du code concernant les fonctionnalités pourrait être déplacée dans un langage server. 

\section{UON}
UON est essentiellement un langage de sérialisation qui est un superset de JSON et un superset partiel de YAML. Il fournit des fonctionnalités supplémentaires utiles pour augmenter l'interopérabilité entre différents types de dispositifs.

\subsection{Pourquoi ?}
Son rôle est d'être utilisé dans l'industrie 4.0. Plus particulièrement dans la communication m2m (machine to machine) ainsi que pour l'IoT (Internet of Things).
Beaucoup d'informations circulent entre ces composants et leurs ressources sont limitées.
C'est ici que ce langage est intéressant. Car il a pour objectif d'encapsuler et représenter l'information avec le plus petit payload possible.
Pour cela UON permet :
\begin{itemize}
    \item De représenter les données sous forme humaine et binaire.
    \item Décrire le payload à travers d'un schéma de validation.
\end{itemize}
Son rôle est donc de représenter des données sous forme la plus minimale pour permettre l'interopérabilité entre machines.

\subsection{Design}
UON est complètement conforme avec JSON et partiellement avec YAML.

\subsection{Types}
Chaque élément est composé d'un type. Et chacun de ces types peut avoir des propriétés.
3 types de propriétés existent :
\begin{itemize}
    \item Presenentation properties.
    \item Validation propeties
    \item Application properties
\end{itemize}

\subsection{Schéma de Validation}
Une des propriétés uniques de UON est l'usage de schéma directement intégré dans le langage.
Le rôle de ce schéma et que les machines se mettent d'accord entre elles sur le format des données à respecter, diminuant ainsi le payload total et s'assurant de la validité des données.

\subsection{Liens}
La spécification comète du projet se trouve ici : \href{https://github.com/uon-language/specification/}{https://github.com/uon-language/specification/}
Et le dépôt du projet : \href{https://github.com/uon-language/specification}{https://github.com/uon-language/specification}


\chapter{Scope de la grammaire}
Pour pouvoir proposer du support pour un nouveau langage, il est nécessaire de savoir sur quoi celui-ci portera. Il est donc important préciser sur quels éléments du langage (grammaire) nous nous focaliserons.
Nous allons donc partir d'une grammaire la plus minimale possible tout en faisant attention à son extensibilité par la suite.
Cette grammaire se trouve dans le fichier UON.g4.

Elle est une adaptation de la grammaire écrite en Lark par l'ancien élève Stéphane Selim pour son travail de bachelor "Parser for a serialization language UON". Son travail se trouve sur :
\href{https://github.com/uon-language/uon-parser}{https://github.com/uon-language/uon-parser}

Elle sera complétée et améliorée après la mise en place des fonctionnalités attendus et si le temps le permet.

Les fonctionnalités implémentées s'appuieront sur cette grammaire. Ceci dans le but de rester cohérents entre eux.

\textbf{Rappel}
La grammaire actuelle nous permet de définir des maps, séquences dans le format json et yaml. D'ajouter des propriétés à des types et également la possibilité de définir un schéma.

\section{Modification}
\textbf{[TODO]}


\chapter{Implémentation}
Dans ce chapitre, nous allons explorer les aspects techniques concernant l'implémentation de fonctionnalités. Nous allons voir également les outils utilisés ainsi que le déploiement de l'extension sur le marketplace.
Ce travail reflète uniquement mon approche personnelle sur la matière. Et ne devrait pas être considérée comme l'unique manière de procéder.

\section{Code}
Le code de l'implémentation est disponible sur le dépôt public suivant : \textbf{[pour l'instant privé]}
Est hébergé sous l'organisation : \textbf{[TODO]}
\textbf{Remarque} : L'implémentation détaillée dans ce rapport pourrait ne plus représenter l'état du dépôt, car ce projet est sujet à évoluer.

\section{Extension}
\textbf{Squelette de base}
VsCode permet de générer un squelette (boilerplate) pour la réalisation d'une extension. Pour ce faire il faut avoir Node.js et Git installés, pour installer Yeoman et VS Code Extension Generator avec la commande :

\begin{lstlisting}[caption={generator-code},label={generator-code}]
npm install -g yo generator-code
\end{lstlisting}

Puis il suffit de saisir la commande :

\begin{lstlisting}
yo code
\end{lstlisting}

et de compléter ce qui est attendu dans le terminal.

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=5cm]{assets/figures/yo-code.png}
    \end{center}
    \caption[Yo Code generator]{\label{yo-code}Yo Code generator}
\end{figure}

Cela nous crée l'arborescence suivante :
\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=5cm]{assets/figures/project-tree.png}
    \end{center}
    \caption[Arborescence du projet]{\label{project-tree}Arborescence du projet}
\end{figure}

Quelques remarques concernant des fichiers et dossiers :
\begin{itemize}
    \item \textbf{.vscode} : Ce trouve le code permettant de lancer l'extension en debug mode dans une nouvelle instance Vscode.
    \item \textbf{.vscodeignore} : Liste les fichiers à ignorer lors de la publication de l'extension.
    \item \textbf{Entension.js} : Fichier principal qui contient la logique de notre extension.
    \item \textbf{CHANGELOG.md} : Écrire ici les modifications apportées lorsqu'on publie une nouvelle version.
    \item \textbf{README.md} : Le readme qui est publié avec l'extension (toutes les infos que l'on voit sur la page sur le marketplace).
\end{itemize}

\subsection{Lancement de l'extension en debug}
On peut lancer une nouvelle fenêtre (f5) qui va contenir notre extension.

Par défaut, l'application généré vient avec du code permettant d'afficher le message suivant : "Hello World from [nom de l'extension]" en bas de l'écran. On l'affiche au travers du command pannel (CTRL + SHIFT + P). On peut s'assurer comme cela que l'implémentation de base fonctionne correctement.
On constate donc que l'on peut lancer notre application au travers d'une commande, mais pour notre cas il sera plus intéressant que vscode nous propose les fonctionnalités à l'ouverture d'un fichier. uon.
Pour cela, il faut donc remplacer le code dans le fichier package.json :

\subsection{Déploiement sur le Marketplace}

\textbf{Prérequis} : Posséder un compte Azure.
Il faut récupérer un Personal Access Token , pour ce faire, il faut créer une \href{https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/create-organization?view=azure-devops}{organisation}.
Puis, créer un access token avec ces paramètres :
\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=5cm]{assets/figures/access-token.png}
    \end{center}
    \caption[Access Token]{\label{access-token}Access Token}
\end{figure}

Créer un publisher avec le même compte qui a créé l'organisation et le token ci-dessus via la \href{https://marketplace.visualstudio.com/manage/publishers/}{management page}

Ajouter la propriété "publisher" et saisir l'id de celui-ci dans le package.json :

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=5cm]{assets/figures/json-publisher.png}
    \end{center}
    \caption[Ajout du publisher dans le fichier package.json]{\label{json-publisher} Ajout du publisher dans le fichier package.json}
\end{figure}

Puis saisir dans le terminal : "vsce login [le nom du publisher]"
Puis "Vsce publish" et "accept"

\textbf{Remarque} : Attention au terminal utilisé. Le terminal de node (git.bash) ne propose pas toujours les options de sélections à l'utilisateur. Dans mon cas il était impossible de saisir le PAT et donc une erreur est affichée.
Il est facile en suite de manager l'extension au travers de la page web :
L'extension apparaitra automatiquement dans le marketplace si elle est publié.

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/manage-publisher.png}
    \end{center}
    \caption[Interface web pour manager l'extension]{\label{manage-publisher} Interface web pour manager l'extension}
\end{figure}


\section{Parser}
Une approche souvent prévilégié pour l'implémentation de fonctionnalités de langage est la génération d'un AST pour en tirer des informations et les utiliser. Pour le générer, un parseur est nécessaire. Étant donné que ce n'est pas le sujet de notre TB, je vais m'aider d'outil existant pour extraire le plus possible de complexité concernant ce sujet.

\subsection{ANTLR}
L'utilisation de ANTLR (ANother Tool for Language Recognition) comme générateur de parser a été choisie pour les raisons suivantes :
\begin{itemize}
    \item C'est un outil populaire est encore utilisé.
    \item Il est disponible en Typescript (\href{https://github.com/tunnelvisionlabs/antlr4ts}{antlr4ts}).
    \item Un moteur de complétion existe avec les parser générés avec antlr. Nous simplifions de grandes étapes pour implémenter l'auto-complétion (\href{https://github.com/mike-lischke/antlr4-c3}{antlr4-c3})
    \item Quelques exemples existent d'implémentation.
    \item La génération est simple. Pour générer un parser (et d'autres fichiers utiles), il suffit d'écrire un fichier contenant une grammaire valide.
\end{itemize}

\subsubsection{Grammaire}
Le fichier de grammaire doit respecter les points suivants : \textbf{[TODO]}

\textbf{Attention} : Utiliser des majuscules pour une règle, correspond à définir un "Lexer rule" et utiliser des minuscules à un  "Parser rule".

Quand le fichier de grammaire est écrit, il suffit de lancer le code suivant :

\begin{lstlisting}
    antlr4ts UON.g4 -no-listener -no-visitor -o generated -Xexact-output-dir
\end{lstlisting}

Il nous génère les fichiers suivants :
\begin{itemize}
    \item UON.interp
    \item UON.tokens
    \item UONLexer.interp
    \item UONLexer.tokens
    \item UONLexer.ts
    \item UONParser.ts
\end{itemize}

\subsection{Arbre (CST)}
étape intérmédiraire.
Antlr va génrer un arbre parsé. (CST pour concrete syntax tree)
Il contient tous les noeuds de la grammaires. Certains sont superflu pour en tirer un sens

Si on veut un AST, on doit parcouir l'arbre (avec des visiteurs ou listeners) pour en tirer un arbre + simple.


\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=2cm]{assets/figures/tree.png}
    \end{center}
    \caption[UON CST]{\label{uon-tree} UON CST}
\end{figure}

\textbf{[TODO]}

\section{Syntax highlighting}
La coloration syntaxique permet que chaque élément du texte soit affiché dans l'éditeur avec une coloration et un style en fonction de son type.
Il y a 2 composantes principales.
\begin{itemize}
    \item La tokenisation qui consiste à séparer le texte en une liste de token.
    \item La thémisation (Theming) qui permet d'attribuer à un token une couleur et un style.
\end{itemize}

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/basic-uon.png}
    \end{center}
    \caption[code UON]{\label{basic-uon} Exemple basique en UON}
\end{figure}


VS code utilise \href{https://macromates.com/manual/en/language_grammars}{Textmate grammars} comme le moteur de tokénisation de la syntaxe.
Cette grammaire a été inventé par l'éditeur TextMate est a été adopté par de nombreux éditeur et IDE.
Elle contient une liste structurée d'expressions régulière qui permet d'associer un scope à un token.
Nous définissons notre grammaire TextMate dans le fichier "uon.tmLanguage.json" qui  se trouve dans le dossier "syntax" à la racine du projet.
Ce fichier doit être référencé à travers du point de contribution "grammar" dans le package.json.

Le but de ce fichier en plus de permettre la coloration syntaxique, et qu'il permet également de rendre l'éditeur de texte "intelligent" quant au contexte dans lequel se trouve le caret. Cela permet d'avoir des comportements différents selon la situation (ex : Pas de bracket closing dans les commentaires).

\subsection{Scope}
Un scope défini le contexte du token et peut-être considéré comme son type.
TextMate fourni une liste de scope communs que de nombreux thèmes ciblent déjà et recommande de les utiliser. Ceci dans le but de permettre à notre langage d'être supporté le plus possible partout.
Les scopes sont souvent imbriqués et c'est le plus spécifique qui est utilisé pour le choix du thème.
Il est possible d'analyser notre code à l'aide du "Scope Inspector" pour visualiser la hiérarchie des scopes pour un token.

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/scope-inspector.png}
    \end{center}
    \caption[Scope inspector]{\label{basic-uon} Le scope inspector sur un exemple de code en UON}
\end{figure}

La section "textmate scopes" montre la liste des scopes utilisés pour le token courant. Le plus spécialisé se trouve au sommet.

Cette fonctionnalité n'est pas considérée comme un "programmatic language feature" et donc n'est pas géré par un langage serveur ou depuis l'api de Vscode. Une des raisons évoquées et que ce mécanisme doit être le plus rapide possible. Et que le faire directement depuis le client garantit une latence faible.

\subsection{Stratégie concernant les noms}
Pour respecter au maximum les conventions attendues et s'assurer qu'une coloration automatique soit appliquée. La stratégie suivante a été adoptée : partir depuis un fichier de thème déjà créer (Thème dark par défaut). Et de réutiliser les scopes.

Ce fichier se trouve sur le dépôt \href{https://github.com/microsoft/vscode/blob/main/extensions/theme-defaults/themes/dark_vs.json}{suivant}.
Mais peut être également généré depuis le contrôle panel.

\subsection{Forcer le choix des couleurs}
\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/manual-settings-color.png}
    \end{center}
    \caption[Choix manuel des couleurs]{\label{manual-settings-color} Choix manuel des couleurs}
\end{figure}

On peut manuellement définir une couleur à un scope dans le fichier package.json.
Cela peut -être intéressant si aucun thème n'est associé de base à un scope.
Il est également possible de créer directement un fichier de thème.

\subsection{Fonctionnement}
\textbf{Exemple simple}

Voici ci-dessous un exemple relativement simple, mais permettant de comprendre le mécanisme général utilisé dans notre fichier uontmLanguage.json :
\begin{lstlisting}
 1  {  scopeName = 'source.untitled';
 2     patterns = (
 3        {  name = 'keyword.control.untitled';
 4           match = '\b(if|while|for|return)\b';
 5        },
 6        {  name = 'string.quoted.double.untitled';
 7           begin = '"';
 8           end = '"';
 9           patterns = (
10              {  name = 'constant.character.escape.untitled';
11                 match = '\\.';
12              }
13           );
14        },
14     );
15  }
\end{lstlisting}

\textbf{"scopeName"} (ligne 1) : Identifiant unique
\textbf{"patterns"} (ligne 2) : C'est un tableau contenant les règles actuelles utilisé pour parser le document. Elles sont appliquées dans l'ordre.
Ces règles peuvent être directement écrites à cet emplacement, mais il est aussi possible de les définir dans le "repository". Puis de les inclure.
\textbf{"repository"} : Un dictionnaire (clé-valeur) de règles.
\textbf{"name"} : Nom du scope.

Contrairement à la première règle qui ne faisait qu'un match, la deuxième définit un début et une fin sur laquelle seront appliquées les règles se trouvant dans le "patterns" suivant (à la ligne 12) . On voit qu'il est donc possible d'imbriquer les règles.

\subsection{Semantic Highlight}

Un point important et qu'il ne faut pas confondre la coloration syntaxique avec ce que l'on nomme "semantic highlighting" qui est une couche que l'on rajoute sur la précédente pour l'améliorer si nécessaire.
Il s'agit d'obtenir des informations plus avancées en analysant plus en détail du code pour fournir une coloration plus précise.
Par exemple avec du code Typescript :

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/semantic-coloration-with.png}
    \end{center}
    \caption[Avec coloration sémantique ]{\label{semantic-coloration-with} Avec coloration sémantique }
\end{figure}

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/semantic-coloration-without.png}
    \end{center}
    \caption[Sans coloration sémantique]{\label{semantic-coloration-without} Sans coloration sémantique}
\end{figure}

On voit à la ligne 10 que la colorisation de la fonction a changé et correspond maintenant à un paramètre d'une fonction.
Cela est donc intéressant pour des langages plus complexes dans leur nature qu'un langage de sérialisation. Une coloration syntaxe suffit amplement dans notre cas. Car se baser sur la structure du document nous donne déjà toutes les informations nécessaires.

\section{Auto-completion}
Cette fonctionnalité fait parti de ce qu'on appelle plus communément \href{https://code.visualstudio.com/docs/editor/intellisense}{"IntelliSense"} qui un terme général désignant diverses fonctions d'édition de code.

Comme mentionné au début de ce document, une approche typique pour implémenter de la complétion est d'utiliser directement un parser du langage.

Mais en complément nous allons utiliser en plus "Antlr4-c3" (Code Completion Core for Antlr4, aussi simplement nommé c3).

Il s'agit d'un moteur de complétion pour les parsers basés sur ANTL4. Le moteur c3 est capable de fournir des candidats de complétions.

Avant il n'y a avait que des solutions customs. Cette librairie a pour objectif de fournir une implémentation commune. Il est disponible comme node module et est écrit en Typescript.

Nous utilisons la version 4 de ANTLR. Elle a comme avantage sur son ancienne version (ANTL3) d'avoir la strucuture de la grammaire directement disponible dans le parser via
un mécanisme de machine à état ATN (Augmented Transition Network). C'est ce méchanisme qui est en coeur du fonctionnement du moteur.

Dans la configuration la plus simple pour l'utiliser, il suffit de lui donner une instance du parser et une position de caret (notre curseur) pour qu'il renvoie les candidats correspondants.
Cette position est l'indice du candidats. L'explication pour le trouver ce trouve dans la séction \hyperref[candidates]{\textbf{Candidats}}

On constate donc que c'est un outil relativement puissant et qui nous simplifie grandement la tâche.

\textbf{Remarque}: On pourrait penser qu'avoir à disposition un parser nous permettrait de récupérer toutes les informations nécessaires au travers d'un AST. Cependant ce n'est pas le cas pour la plupart des scénarios.
Nous pouvons savoir quels sont les tokens valide à un emplacement (ce qui est suffisant pour nous). Mais pour certains langages, des informations manquent. Par exemple des noms de classe, des objets de base de données, des membres de classes, des fonctions, etc. ne sont pas représentés dans la grammaire. 

Ci-dessous Un ATN d'une séquence :

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/seq_ATN.png}
    \end{center}
    \caption[ATN d'une séquence]{\label{seq_ATN} ATN d'une séquence}
\end{figure}

La seule contrainte est qu'il est nécessaire que tout le code se trouvant avant le curseur soit correct. Mais ce qui se trouve à la suite peut être erroné.
Ainsi, nous pouvons revenir n'importe où dans le code, car la partie se trouvant après le curseur n'est pas prise en compte et la rédaction du code précédente est normalement correcte.
De plus, actuellement, nous n'avons pas de suggestions qui dépendrais de ce qui se trouve après le curseur.
Car par exemple dans l'exemple suivant pour du code SQL :

\begin{lstlisting}
SELECT | FROM USER // ("|" étant le curseur)
\end{lstlisting}

Dans ce scénario des suggestions liées à la table USER devrait être proposé et donc un traitement particulier devrait être fait.
La seule chose qui doit donc être correcte est la structure du code. C'est-à-dire que l'ordre des éléments attendus est respecté.
Il semble normal que la complétion n'ait pas lieu si le code précédent est gravement erroné pouvant être un indice à l'utilisateur. Cependant il doit quand même supporter une certaine marge d'erreur. Dans notre cas, les erreurs sur les valeurs (par exemple une propriété "max : 12a") pourraient être omises en utilisant une grammaire qui nous permet d'avoir des types supportant le plus de symboles possibles. Ainsi même si cela est faux syntaxiquement en UON, cela ne bloque pas le processus de l'auto-complétion.

\subsection{Mécanisme automatique}
VsCode va automatiquement filtrer les suggestions pendant la saisie.
Par défaut il propose également des symboles déjà existants dans le code dans ses suggestions.

\subsection{Gestion des erreurs}
On peut ajouter au parser un "ErrorListener".
Par défaut c'est cette stratégie d'erreur qui est appliquée :
\href{https://github.com/tunnelvisionlabs/antlr4ts/blob/master/src/DefaultErrorStrategy.ts}{https://github.com/tunnelvisionlabs/antlr4ts/blob/master/src/DefaultErrorStrategy.ts}

Mais on peut l'étendre pour redéfinir les fonctions.
\textbf{[TODO]}

\subsection{Problème}
Dans certains cas lorsque l'on trigger de l'autocomplétion quand le curseur se trouve collé à du texte. L'éditeur affiche le message "no suggestions" alors que le provider contient une liste de suggestions possible.
\textbf{[TODO]}

\subsection{Snippets}
Il est possible d'ajouter des snippets sous Vscode. C'est-à-dire des templates qui nous permettent de générer du code prédéfini. Puis de les ajouter aux suggestions.
C'est utile si à un moment donné on a le choix entre plusieurs suggestions et que l'on veut tous les avoir d'un coup.
Par exemple, on peut en UON, ajouter des attributs à un schéma :

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/snippet-suggestion.png}
    \end{center}
    \caption[Suggestion d'un snippet]{\label{snippet-suggestion} Suggestion d'un snippet}
\end{figure}

Cependant toute la difficulté et de proposer ces suggestions au bon moment, car ne faisant pas partie du moteur de complétions d'antlr. Une idée et de se baser sur le dernier token reconnu. On pourrait ici savoir qu'il est le moment d'ajouter ce snippet, si le dernier token est de type "!schema".

\subsection{Triggers}
L'éditeur va trigger automatiquement l'autocomplétions en appelant le provider lorsque l'on saisit plusieurs caractères. Il aussi possible de l'activer manuellement en exécutant la commande "ctr + space".
On peut aussi ajouter au provider des symboles qui vont trigger son activation. Les symboles espace et de retour à la ligne ont été défini comme triggers, car cela semble assez naturel dans ce langage. Cependant il ne s'agit seulement d'une appréciation personnelle.

\subsection{Candidats}\label{candidates}

Actuellement pour connaitre l'indice du ou des prochains candidats, on récupère le flux des tokens (tokenStream) trouvé lors du parsing.
Puis, on récupère dans un tableau chaque token individuellement (y compris les espaces).

Cependant lorsque l'utilisateur écrit et que cela trigger l'autocomplétion, le texte parsé est souvent inccorect, car le dernier élément saisi n'est pas encore complet.

Grâce à la taille du tableau et en se basant sur les erreurs qui ont été généré, on peut déduire l'indice du ou des prochains tokens que l'on peut afficher.

\subsubsection{Index du candidat}
L'indexation est gérée de 2 manières différentes. En fonction de la prise en compte de l'espace ou non.

\begin{figure}[!ht]
    \begin{center}
        \includegraphics[width=10cm]{assets/figures/candidat-index.png}
    \end{center}
    \caption[Indexation des candidats]{\label{candidat-index} Indexation des candidats}
\end{figure}

Cela va dépendre si on décide d'ignorer ou non les espaces dans la grammaire g4.
Les dévelopeurs de c3 recommandent de pas ignorer les espaces. Car cela permet de gérer plus de cas particuliers.

\section{Document outlining}
\textbf{[TODO]}

\section{Info on Hover}
\textbf{[TODO]}

\section{Fonctionnalités triviales}
Il s'agit de fonctionnalités couramment disponibles dans un support de langage. Leur implémentation est relativement simple et rapide et n'a donc pas été mentionnée dans le cahier des charges.

Les suivantes ont été implémentées :
\textbf{Comment}
\begin{itemize}
    \item Il est possible de commenter du code sous forme de ligne.
    \item Il est possible de commenter et décommenter du code (Toggling)
\end{itemize}

\textbf{Symbol pairs}
\begin{itemize}
    \item Il est possible de faire la correspondance pour certaines paires de symboles à l'aide d'une indication visuelle. (Matching)
    \item Certains symboles du langage doivent être automatiquement complétés si l'utilisateur saisit le premier élément de celle-ci. (Autoclosing)
\end{itemize}

\textbf{Code folding}
\begin{itemize}
    \item Cacher un bloc de code sur une ligne en fonction de son niveau d'indentation.
\end{itemize}

Pour pouvoir les implémenter, il suffit d'éditer un fichier de configuration json (language-configuration.json) puis  éditer le fichier package.json afin qu'il référence ce fichier sous le point "contribution".

\chapter{Intégration continue}

\section{Autocomplétion}
Applique la même méthodologie de antlr4-ts : \href{https://github.com/mike-lischke/antlr4-c3/tree/master/test}{https://github.com/mike-lischke/antlr4-c3/tree/master/test}
\textbf{[TODO]}

\section{Syntax highlight}
\textbf{[TODO]}

\section{Outline view}
Teste que l'arbre syntaxique reçu est celui attendu pour un code.
\textbf{[TODO]}

\section{Information Hover}
Tester que l'élément on Hover soit celui attendu
\textbf{[TODO]}

\chapter{Conclusion}
\textbf{[TODO]}

%% \vfil
%% \hspace{8cm}\makeatletter\@author\makeatother\par
%% \hspace{8cm}\begin{minipage}{5cm}
%%if
% Place pour signature numérique
%%\printsignature
%%fi
%% \end{minipage}
%% \clearpage


%%if
\chapter{Annexe}
\dots

%% \let\cleardoublepage\clearpage
%% \backmatter

%% \label{glossaire}
%% \printnoidxglossary
%% \printbibliography
%% \label{index}
%% \printindex

\end{document}
